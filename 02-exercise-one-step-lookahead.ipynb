{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":17592,"databundleVersionId":899221,"sourceType":"competition"}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This notebook is an exercise in the [Intro to Game AI and Reinforcement Learning](https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning) course.  You can reference the tutorial at [this link](https://www.kaggle.com/alexisbcook/one-step-lookahead).**\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"# Introduction\n\nIn the tutorial, you learned how to define a simple heuristic that the agent used to select moves.  In this exercise, you'll check your understanding and make the heuristic more complex.\n\nTo get started, run the code cell below to set up our feedback system.","metadata":{}},{"cell_type":"code","source":"from learntools.core import binder\nbinder.bind(globals())\nfrom learntools.game_ai.ex2 import *","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T06:32:07.058566Z","iopub.execute_input":"2025-08-28T06:32:07.058864Z","iopub.status.idle":"2025-08-28T06:32:42.702420Z","shell.execute_reply.started":"2025-08-28T06:32:07.058834Z","shell.execute_reply":"2025-08-28T06:32:42.701448Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 1) A more complex heuristic\n\nThe heuristic from the tutorial looks at all groups of four adjacent grid locations on the same row, column, or diagonal and assigns points for each occurrence of the following patterns:\n\n<center>\n<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/vzQa4ML.png\" width=60%><br/>\n</center>\n\nIn the image above, we assume that the agent is the red player, and the opponent plays yellow discs.\n\nFor reference, here is the `get_heuristic()` function from the tutorial:\n```python\ndef get_heuristic(grid, mark, config):\n    num_threes = count_windows(grid, 3, mark, config)\n    num_fours = count_windows(grid, 4, mark, config)\n    num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n    score = num_threes - 1e2*num_threes_opp + 1e6*num_fours\n    return score\n```\n\nIn the `get_heuristic()` function, `num_fours`, `num_threes`, and `num_threes_opp` are the number of windows in the game grid that are assigned 1000000, 1, and -100 point(s), respectively. \n    \nIn this tutorial, you'll change the heuristic to the following (where you decide the number of points to apply in each of `A`, `B`, `C`, `D`, and `E`).  You will define these values in the code cell below.\n\n<center>\n<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/FBoWr2f.png\" width=80%><br/>\n</center>\n    \n\nTo check your answer, we use your values to create a heuristic function as follows:\n\n```python\ndef get_heuristic_q1(grid, col, mark, config):\n    num_twos = count_windows(grid, 2, mark, config)\n    num_threes = count_windows(grid, 3, mark, config)\n    num_fours = count_windows(grid, 4, mark, config)\n    num_twos_opp = count_windows(grid, 2, mark%2+1, config)\n    num_threes_opp = count_windows(grid, 3, mark%2+1, config)\n    score = A*num_fours + B*num_threes + C*num_twos + D*num_twos_opp + E*num_threes_opp\n    return score\n```\n\nThis heuristic is then used to create an agent, that competes against the agent from the tutorial in 50 different game rounds.  In order to be marked correct, \n- your agent must win at least half of the games, and\n- `C` and `D` must both be nonzero.","metadata":{}},{"cell_type":"code","source":"# TODO: Assign your values here\n# There are many values that can work!\nA = 1e10\nB = 1e4\nC = 1e2\nD = -1\nE = -1e6\n\n# Check your answer (this will take a few seconds to run!)\nq_1.check()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T06:35:56.998220Z","iopub.execute_input":"2025-08-28T06:35:56.998509Z","iopub.status.idle":"2025-08-28T06:36:08.403411Z","shell.execute_reply.started":"2025-08-28T06:35:56.998489Z","shell.execute_reply":"2025-08-28T06:36:08.402521Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Lines below will give you a hint or solution code\nq_1.hint()\n#q_1.solution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T06:36:21.759494Z","iopub.execute_input":"2025-08-28T06:36:21.759838Z","iopub.status.idle":"2025-08-28T06:36:21.767792Z","shell.execute_reply.started":"2025-08-28T06:36:21.759808Z","shell.execute_reply":"2025-08-28T06:36:21.766991Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 2) Does the agent win?\n\nConsider the game board below.  \n\n<center>\n<img src=\"https://storage.googleapis.com/kaggle-media/learn/images/AlnaQ3J.png\" width=30%><br/>\n</center>\n\nSay the agent uses red discs, and it's the agent's turn.  \n- If the agent uses the heuristic **_from the tutorial_**, does it win or lose the game?\n- If the agent uses the heuristic **_that you just implemented_**, does it win or lose the game?","metadata":{}},{"cell_type":"code","source":"q_2.hint()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T06:37:24.221983Z","iopub.execute_input":"2025-08-28T06:37:24.222293Z","iopub.status.idle":"2025-08-28T06:37:24.229675Z","shell.execute_reply.started":"2025-08-28T06:37:24.222271Z","shell.execute_reply":"2025-08-28T06:37:24.228727Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check your answer (Run this code cell to receive credit!)\nq_2.solution()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T06:37:29.333107Z","iopub.execute_input":"2025-08-28T06:37:29.333412Z","iopub.status.idle":"2025-08-28T06:37:29.340765Z","shell.execute_reply.started":"2025-08-28T06:37:29.333389Z","shell.execute_reply":"2025-08-28T06:37:29.339891Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3) Submit to the competition\n\nNow, it's time to submit an agent to the competition!  Use the next code cell to define an agent.  (You can see an example of how to write a valid agent in **[this notebook](https://www.kaggle.com/alexisbcook/create-a-connectx-agent)**.)\n\nYou're encouraged to use what you learned in the first question of this exercise to write an agent.  Use the code from the tutorial as a starting point. ","metadata":{}},{"cell_type":"code","source":"def my_agent(obs, config):\n    \n    # Your code here: Amend the agent!\n    # 1) Loops over all valid moves.\n    # 2) Simulates dropping a piece in that column.\n    # 3) Scores the resulting board using get_heuristic_q1.\n    # 4) Picks the move with the highest score.\n    \n    import random\n    import numpy as np\n\n    def drop_piece(board, col, mark):\n        # Return a new grid after dropping a piece in column.\n        new_board = board[:]\n        for row in range(config.rows - 1, -1, -1):\n            if new_board[row * config.columns + col] == 0:\n                new_board[row * config.columns + col] = mark\n                break\n        return new_board\n\n    valid_moves = [c for c in range(config.columns) if obs.board[c] == 0]\n\n    best_score = -float(\"inf\")\n    best_moves = []\n\n    for col in valid_moves:\n        # Simulate move!\n        new_board = drop_piece(list(obs.board), col, obs.mark)\n        # Convert flat board into 2D grid.\n        grid = np.asarray(new_board).reshape(config.rows, config.columns)\n\n        score = get_heuristic_q1(grid, col, obs.mark, config)\n        if score > best_score:\n            best_score = score\n            best_moves = [col]\n        elif score == best_score:\n            best_moves.append(col)\n\n    return random.choice(best_moves)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T06:43:17.097415Z","iopub.execute_input":"2025-08-28T06:43:17.098217Z","iopub.status.idle":"2025-08-28T06:43:17.105304Z","shell.execute_reply.started":"2025-08-28T06:43:17.098190Z","shell.execute_reply":"2025-08-28T06:43:17.104472Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run this code cell to get credit for creating an agent\nq_3.check()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T06:43:21.200248Z","iopub.execute_input":"2025-08-28T06:43:21.201011Z","iopub.status.idle":"2025-08-28T06:43:21.207193Z","shell.execute_reply.started":"2025-08-28T06:43:21.200981Z","shell.execute_reply":"2025-08-28T06:43:21.206442Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Run the next code cell to convert your agent to a submission file.","metadata":{}},{"cell_type":"code","source":"import inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"a\" if os.path.exists(file) else \"w\") as f:\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(my_agent, \"submission.py\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-28T06:43:25.349729Z","iopub.execute_input":"2025-08-28T06:43:25.350043Z","iopub.status.idle":"2025-08-28T06:43:25.356680Z","shell.execute_reply.started":"2025-08-28T06:43:25.350020Z","shell.execute_reply":"2025-08-28T06:43:25.355841Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Then, follow these steps to submit your agent to the competition:\n1. Begin by clicking on the **Save Version** button in the top right corner of the window.  This will generate a pop-up window.  \n2. Ensure that the **Save and Run All** option is selected, and then click on the **Save** button.\n3. This generates a window in the bottom left corner of the notebook.  After it has finished running, click on the number to the right of the **Save Version** button.  This pulls up a list of versions on the right of the screen.  Click on the ellipsis **(...)** to the right of the most recent version, and select **Open in Viewer**.  This brings you into view mode of the same page. You will need to scroll down to get back to these instructions.\n4. Click on the **Data** tab near the top of the screen.  Then, click on the file you would like to submit, and click on the **Submit** button to submit your results to the leaderboard.\n\nYou have now successfully submitted to the competition!\n\nIf you want to keep working to improve your performance, select the **Edit** button in the top right of the screen. Then you can change your code and repeat the process. There's a lot of room to improve, and you will climb up the leaderboard as you work.\n\n\nGo to **\"My Submissions\"** to view your score and episodes being played.\n\n# Keep going\n\nMove on to **[develop a longer-term strategy](https://www.kaggle.com/alexisbcook/n-step-lookahead)** with the minimax algorithm.","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/intro-to-game-ai-and-reinforcement-learning/discussion) to chat with other learners.*","metadata":{}}]}